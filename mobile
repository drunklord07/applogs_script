#!/usr/bin/env python3
import re
import json
from docx import Document
from docx.shared import RGBColor
import xlsxwriter
from tqdm import tqdm

# === CONFIG ===
INPUT_FILE   = "input.txt"
OUTPUT_XLSX  = "ParsedLogs.xlsx"
OUTPUT_DOCX  = "ParsedLogs.docx"

# Updated mobile regex: no letter/digit before or after
MOBILE_REGEX = re.compile(
    r'(?<![A-Za-z0-9])'            # not preceded by letter/digit
    r'((?:\+91[\-\s]?|91[\-\s]?|0)?[6-9]\d{9})'
    r'(?![A-Za-z0-9])'             # not followed by letter/digit
)

# Matches start of a log line (with optional ms)
TIMESTAMP_RE = re.compile(r'^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}(?:,\d+)?\s')

# === HELPERS ===
def flatten_json(obj, prefix=""):
    flat = {}
    if isinstance(obj, dict):
        for k, v in obj.items():
            path = f"{prefix}{k}"
            if isinstance(v, (dict, list)):
                flat.update(flatten_json(v, path + "."))
            else:
                flat[path] = v
    elif isinstance(obj, list):
        for i, item in enumerate(obj):
            flat.update(flatten_json(item, f"{prefix}[{i}]."))
    return flat

def detect_type(line):
    if ' cid=[' in line and ' txn=[' in line:
        return 'A'
    if '~#~' in line:
        return 'B'
    if 'UKC:' in line:
        return 'C'
    return None

# === PARSERS ===
def parse_type_a(line):
    m = re.match(
        r'^(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}(?:,\d+)?)\s+'
        r'(?P<level>\w+)\s+\[(?P<thread>[^\]]+)\]\s+'
        r'cid=\[(?P<cid>[^\]]*)\]\s+'
        r'txn=\[(?P<txn>[^\]]*)\]\s+'
        r'(?P<logger>\w+)\s*:\s*(?P<message>.+)$',
        line
    )
    if not m:
        raise ValueError("Type A parse error")
    return m.groupdict()

def parse_type_b(meta_line, rest_lines):
    # 1) Extract timestamp, thread, level, logger from meta_line
    ts_m = re.match(r'^(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d+)', meta_line)
    timestamp = ts_m.group(1) if ts_m else ""
    br = re.search(r'\[([^\]]+)\]\s*\[([^\]]+)\]\s*\[([^\]]+)\]', meta_line)
    thread, level, logger = (br.group(1), br.group(2).strip(), br.group(3)) if br else ("","","")
    # 2) metadata: text after "] - "
    metadata = meta_line.split('] - ', 1)[1]
    # 3) payload: lines starting with "~#~", strip exactly that prefix
    payload_lines = []
    for _, txt in rest_lines:
        if txt.startswith('~#~'):
            payload_lines.append(txt[3:])  # remove "~#~"
    payload = "\n".join(payload_lines)

    # 4) attempt to flatten JSON (ignore decode errors)
    json_fields = {}
    try:
        obj = json.loads(payload)
        json_fields = flatten_json(obj)
    except json.JSONDecodeError:
        pass

    # 5) build record
    rec = {
        "timestamp": timestamp,
        "thread":    thread,
        "level":     level,
        "logger":    logger,
        "metadata":  metadata,
        "payload":   payload
    }
    # merge any json.<path> fields
    for k, v in json_fields.items():
        rec[f"json.{k}"] = v
    return rec

def parse_type_c(line):
    m = re.match(
        r'^(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d+)\s+'
        r'\[(?P<thread>[^\]]+)\]\s+'
        r'\[(?P<level>\w+)\s*\]\s+'
        r'\[(?P<logger>[^\]]+)\]\s*-\s*(?P<rest>.+)$',
        line
    )
    if not m:
        raise ValueError("Type C parse error")
    info = m.groupdict()
    parts = [p.strip() for p in info['rest'].split(',')]
    return {
        "timestamp":     info['timestamp'],
        "thread":        info['thread'],
        "level":         info['level'],
        "logger":        info['logger'],
        "ukc":           parts[0].split(':',1)[1] if ':' in parts[0] else parts[0],
        "request_time":  parts[1] if len(parts)>1 else "",
        "response_time": parts[2] if len(parts)>2 else "",
        "masked_id":     parts[3] if len(parts)>3 else "",
        "operation":     parts[4] if len(parts)>4 else "",
        "other":         ",".join(parts[5:]) if len(parts)>5 else ""
    }

# === MAIN ===
def main():
    # read all non-blank lines
    raw = []
    with open(INPUT_FILE, encoding='utf-8', errors='ignore') as f:
        for idx, line in enumerate(f, start=1):
            txt = line.rstrip('\n')
            if txt.strip():
                raw.append((idx, txt))

    # group by timestamp start
    logs = []
    for ln_no, txt in raw:
        if TIMESTAMP_RE.match(txt):
            logs.append({"start_line": ln_no, "lines": [(ln_no, txt)]})
        else:
            if logs:
                logs[-1]["lines"].append((ln_no, txt))

    total_logs = len(logs)
    parsed     = []
    errors     = []

    # parse each log
    for rec in tqdm(logs, desc="Parsing logs"):
        start_ln = rec["start_line"]
        meta     = rec["lines"][0][1]
        rest     = rec["lines"][1:]
        ttype    = detect_type(meta)

        try:
            if ttype == 'A':
                data = parse_type_a(meta)
            elif ttype == 'B':
                data = parse_type_b(meta, rest)
            elif ttype == 'C':
                data = parse_type_c(meta)
            else:
                raise ValueError("Unknown log type")
        except Exception as e:
            errors.append({
                "line_no": start_ln,
                "raw":     "\n".join(l for _,l in rec["lines"]),
                "error":   str(e)
            })
            continue

        # scan for mobiles
        for k, v in data.items():
            for m in MOBILE_REGEX.finditer(str(v)):
                parsed.append({
                    "line_no":  start_ln,
                    "type":     ttype,
                    **data,
                    "match":    m.group(1),
                    "field":    k
                })

    # write Excel
    wb = xlsxwriter.Workbook(OUTPUT_XLSX)
    ws1 = wb.add_worksheet("ParsedLogs")
    if parsed:
        # dynamic headers
        headers = []
        for row in parsed:
            for h in row:
                if h not in headers:
                    headers.append(h)
        for c, h in enumerate(headers):
            ws1.write(0, c, h)
        red_fmt = wb.add_format({"font_color":"red"})
        for r, row in enumerate(parsed, start=1):
            for c, h in enumerate(headers):
                val = row.get(h, "")
                ws1.write(r, c, val, red_fmt if h=="match" else None)
    # Errors sheet
    ws2 = wb.add_worksheet("Errors")
    ws2.write_row(0, 0, ["line_no", "raw", "error"])
    for r, err in enumerate(errors, start=1):
        ws2.write(r, 0, err["line_no"])
        ws2.write(r, 1, err["raw"])
        ws2.write(r, 2, err["error"])
    wb.close()

    # write Word
    doc = Document()
    for row in tqdm(parsed, desc="Generating Word"):
        p = doc.add_paragraph()
        p.add_run(f"{row['line_no']} | {row['timestamp']} | ")
        mr = p.add_run(row['match'])
        mr.font.color.rgb = RGBColor(255, 0, 0)
        p.add_run(f"  [{row['field']}]")
    doc.save(OUTPUT_DOCX)

    # summary
    print(f"Total logs           : {total_logs}")
    print(f"Total mobile matches : {len(parsed)}")
    print(f"Parse errors         : {len(errors)}")

if __name__ == "__main__":
    main()
