#!/usr/bin/env python3
import re
import json
from docx import Document
from docx.shared import RGBColor
import xlsxwriter
from tqdm import tqdm

# === CONFIG ===
INPUT_FILE   = "input.txt"
OUTPUT_XLSX  = "ParsedLogs.xlsx"
OUTPUT_DOCX  = "ParsedLogs.docx"

# Your mobile regex:
MOBILE_REGEX = re.compile(r'(?<!\d)((?:\+91[\-\s]?|91[\-\s]?|0)?[6-9]\d{9})(?!\d)')

# Timestamp at start, optionally with milliseconds
TIMESTAMP_RE = re.compile(r'^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}(?:,\d+)?\s')

# === HELPERS ===
def flatten_json(obj, prefix=""):
    flat = {}
    if isinstance(obj, dict):
        for k, v in obj.items():
            path = f"{prefix}{k}"
            if isinstance(v, (dict, list)):
                flat.update(flatten_json(v, path + "."))
            else:
                flat[path] = v
    elif isinstance(obj, list):
        for i, item in enumerate(obj):
            flat.update(flatten_json(item, f"{prefix}[{i}]."))
    return flat

def detect_type(meta_line: str):
    if ' cid=[' in meta_line and ' txn=[' in meta_line:
        return 'A'
    if '~#' in meta_line:
        return 'B'
    if 'UKC:' in meta_line:
        return 'C'
    return None

# === PARSERS ===
def parse_type_a(line: str):
    m = re.match(
        r'^(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) '
        r'(?P<level>\w+) \[(?P<thread>[^\]]+)\] '
        r'cid=\[(?P<cid>[^\]]*)\] '
        r'txn=\[(?P<txn>[^\]]*)\] '
        r'(?P<logger>\w+)\s*:\s*(?P<message>.+)$',
        line
    )
    if not m:
        raise ValueError("Failed to parse Type A")
    return m.groupdict()

def parse_type_b(meta: str, payload: str):
    # Meta part
    mm = re.match(
        r'^(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d+)\s+'
        r'\[(?P<thread>[^\]]+)\]\s+'
        r'\[(?P<level>\w+)\s*\]\s+'
        r'\[(?P<logger>[^\]]+)\]\s*-\s*(?P<rest>.+)$',
        meta
    )
    if not mm:
        raise ValueError("Failed to parse Type B meta")
    info = mm.groupdict()

    parts = info['rest'].split('~#')
    service   = parts[0] if len(parts)>0 else ""
    endpoint  = parts[1] if len(parts)>1 else ""
    record_id = parts[2] if len(parts)>2 else ""
    start_ts  = parts[3] if len(parts)>3 else ""
    end_ts    = parts[4] if len(parts)>4 else ""

    # JSON payload
    try:
        obj = json.loads(payload)
    except Exception as e:
        raise ValueError(f"JSON error: {e}")
    flat = flatten_json(obj)

    d = {
        "timestamp":  info['timestamp'],
        "level":      info['level'],
        "thread":     info['thread'],
        "logger":     info['logger'],
        "service":    service,
        "endpoint":   endpoint,
        "record_id":  record_id,
        "start_ts":   start_ts,
        "end_ts":     end_ts,
    }
    # merge flattened JSON under json.*
    for k, v in flat.items():
        d[f"json.{k}"] = v
    return d

def parse_type_c(line: str):
    mm = re.match(
        r'^(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d+)\s+'
        r'\[(?P<thread>[^\]]+)\]\s+'
        r'\[(?P<level>\w+)\s*\]\s+'
        r'\[(?P<logger>[^\]]+)\]\s*-\s*(?P<rest>.+)$',
        line
    )
    if not mm:
        raise ValueError("Failed to parse Type C meta")
    info = mm.groupdict()
    cols = [c.strip() for c in info['rest'].split(',')]
    ukc         = cols[0].split(':',1)[1] if ':' in cols[0] else cols[0]
    req_t       = cols[1] if len(cols)>1 else ""
    resp_t      = cols[2] if len(cols)>2 else ""
    masked_id   = cols[3] if len(cols)>3 else ""
    operation   = cols[4] if len(cols)>4 else ""
    other       = ",".join(cols[5:]) if len(cols)>5 else ""
    return {
        "timestamp":    info['timestamp'],
        "level":        info['level'],
        "thread":       info['thread'],
        "logger":       info['logger'],
        "ukc":          ukc,
        "request_time": req_t,
        "response_time":resp_t,
        "masked_id":    masked_id,
        "operation":    operation,
        "other":        other,
    }

# === MAIN ===
def main():
    # 1) Load all non-blank lines with their numbers
    raw_lines = []
    with open(INPUT_FILE, encoding='utf-8', errors='ignore') as f:
        for idx, raw in enumerate(f, start=1):
            ln = raw.rstrip('\r\n')
            if ln.strip():
                raw_lines.append((idx, ln))

    # 2) Group into "logs" by timestamp at start
    records = []
    for ln_no, text in raw_lines:
        if TIMESTAMP_RE.match(text):
            records.append({"start_line": ln_no, "lines": [(ln_no, text)]})
        else:
            if records:
                records[-1]["lines"].append((ln_no, text))
    total_logs = len(records)

    parsed = []
    errors = []

    # 3) Parse each record with a progress bar
    for rec in tqdm(records, desc="Parsing logs"):
        start_ln = rec["start_line"]
        meta_line = rec["lines"][0][1]
        rest_lines = [l for _, l in rec["lines"][1:]]
        payload = "\n".join(rest_lines).strip()
        t = detect_type(meta_line)
        try:
            if t == 'A':
                data = parse_type_a(meta_line)
            elif t == 'B':
                data = parse_type_b(meta_line, payload)
            elif t == 'C':
                data = parse_type_c(meta_line)
            else:
                raise ValueError("Unknown log type")
        except Exception as e:
            errors.append({
                "line_no": start_ln,
                "raw":     "\n".join([l for _,l in rec["lines"]]),
                "error":   str(e)
            })
            continue

        # 4) Scan for mobile matches
        for key, val in data.items():
            for m in MOBILE_REGEX.finditer(str(val)):
                parsed.append({
                    "start_line":  start_ln,
                    "type":        t,
                    **data,
                    "match":       m.group(1),
                    "field":       key
                })

    # 5) Write Excel (one sheet + Errors)
    wb = xlsxwriter.Workbook(OUTPUT_XLSX)
    # ParsedLogs
    ws = wb.add_worksheet("ParsedLogs")
    if parsed:
        # build header order dynamically
        headers = []
        for row in parsed:
            for k in row:
                if k not in headers:
                    headers.append(k)
        # write headers
        for c, h in enumerate(headers):
            ws.write(0, c, h)
        red = wb.add_format({"font_color":"red"})
        # write rows
        for r, row in enumerate(parsed, start=1):
            for c, h in enumerate(headers):
                v = row.get(h, "")
                if h == "match":
                    ws.write(r, c, v, red)
                else:
                    ws.write(r, c, v)
    # Errors
    ws2 = wb.add_worksheet("Errors")
    ws2.write_row(0, 0, ["line_no", "raw", "error"])
    for r, err in enumerate(errors, start=1):
        ws2.write(r, 0, err["line_no"])
        ws2.write(r, 1, err["raw"])
        ws2.write(r, 2, err["error"])
    wb.close()

    # 6) Write Word doc with a progress bar
    doc = Document()
    for row in tqdm(parsed, desc="Generating Word"):
        p = doc.add_paragraph()
        p.add_run(f"{row['start_line']} | {row['timestamp']} | ")
        mrun = p.add_run(row["match"])
        mrun.font.color.rgb = RGBColor(255, 0, 0)
        p.add_run(f"  [{row['field']}]")
    doc.save(OUTPUT_DOCX)

    # 7) Summary
    print(f"Number of logs      : {total_logs}")
    print(f"Total mobile matches: {len(parsed)}")
    print(f"Total parse errors  : {len(errors)}")

if __name__ == "__main__":
    main()
