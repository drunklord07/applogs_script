#!/usr/bin/env python3
import re
import json
import xlsxwriter
from tqdm import tqdm
from docx import Document
from docx.shared import RGBColor

# === CONFIG ===
INPUT_FILE  = "input.txt"
OUTPUT_XLSX = "ParsedLogs_Mobile.xlsx"
OUTPUT_DOCX = "ParsedLogs_Mobile.docx"

# Mobile regex: no letter/digit immediately before/after
MOBILE_INNER = r'(?:\+91[\-\s]?|91[\-\s]?|0)?[6-9]\d{9}'
MOBILE_REGEX = re.compile(rf'(?<![A-Za-z0-9])({MOBILE_INNER})(?![A-Za-z0-9])')

# To find key= candidates inside a fragment
KV_CANDIDATE_RE = re.compile(r'\b([A-Za-z0-9_]+)\s*=')

# Header: timestamp, thread, level, skip extras, logger
HEADER_RE = re.compile(
    r'^(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}(?:,\d+)?)\s+'
    r'\[(?P<thread>[^\]]+)\]\s+'
    r'\[(?P<level>[^\]]+)\]\s+'
    r'(?:\[[^\]]*\]\s+)*'
    r'\[(?P<logger>[^\]]+)\]\s*-\s*'
    r'(?P<rest>.+)$'
)

def flatten_json(obj, prefix=""):
    out = {}
    if isinstance(obj, dict):
        for k, v in obj.items():
            path = f"{prefix}{k}"
            if isinstance(v, (dict, list)):
                out.update(flatten_json(v, path + "."))
            else:
                out[path] = v
    elif isinstance(obj, list):
        for i, item in enumerate(obj):
            out.update(flatten_json(item, f"{prefix}[{i}]."))
    return out

def extract_fragments(s):
    frags = []
    pos = 0
    while True:
        start = s.find("{", pos)
        if start < 0:
            break
        depth = 0
        end = start
        for i, ch in enumerate(s[start:], start):
            if ch == "{":
                depth += 1
            elif ch == "}":
                depth -= 1
                if depth == 0:
                    end = i + 1
                    break
        if depth != 0:
            break
        frags.append(s[start:end])
        pos = end
    return frags

def find_nearest_key(frag, match_start):
    """
    Among all key= occurrences whose '=' is before match_start,
    pick the one closest to it.
    """
    best = None
    best_pos = -1
    for m in KV_CANDIDATE_RE.finditer(frag):
        eq_pos = m.end() - 1
        if eq_pos < match_start and eq_pos > best_pos:
            best_pos = eq_pos
            best = m.group(1)
    return best

def main():
    lines = []
    with open(INPUT_FILE, encoding="utf-8", errors="ignore") as f:
        for ln_no, raw in enumerate(f, 1):
            txt = raw.rstrip("\n")
            if txt.strip():
                lines.append((ln_no, txt))

    parsed = []
    errors = []

    for ln_no, line in tqdm(lines, desc="Parsing lines"):
        header = HEADER_RE.match(line)
        if not header:
            errors.append({"line_no": ln_no, "raw": line, "error": "Header parse failed"})
            continue
        hdr = header.groupdict()
        rest = hdr.pop("rest")

        for frag in extract_fragments(rest):
            # flatten JSON (if valid)
            leaves = {}
            try:
                obj = json.loads(frag)
                leaves = flatten_json(obj)
            except json.JSONDecodeError:
                pass

            # scan fragment raw text
            for mo in MOBILE_REGEX.finditer(frag):
                num = mo.group(1)
                start = mo.start()
                # check for leaf-path matches
                paths = [p for p, v in leaves.items() if str(v).find(num) != -1]
                if paths:
                    for field in paths:
                        parsed.append({
                            "line_no":  ln_no,
                            "timestamp": hdr["timestamp"],
                            "thread":    hdr["thread"],
                            "level":     hdr["level"],
                            "logger":    hdr["logger"],
                            "field":     field,
                            "match":     num
                        })
                else:
                    key = find_nearest_key(frag, start) or "fragment"
                    parsed.append({
                        "line_no":  ln_no,
                        "timestamp": hdr["timestamp"],
                        "thread":    hdr["thread"],
                        "level":     hdr["level"],
                        "logger":    hdr["logger"],
                        "field":     key,
                        "match":     num
                    })

    # write Excel
    wb = xlsxwriter.Workbook(OUTPUT_XLSX)
    ws1 = wb.add_worksheet("ParsedLogs")
    if parsed:
        cols = list(parsed[0].keys())
        for c, h in enumerate(cols):
            ws1.write(0, c, h)
        red = wb.add_format({"font_color": "red"})
        for r, row in enumerate(parsed, 1):
            for c, h in enumerate(cols):
                ws1.write(r, c, row[h], red if h == "match" else None)

    ws2 = wb.add_worksheet("Errors")
    ws2.write_row(0, 0, ["line_no", "raw", "error"])
    for r, e in enumerate(errors, 1):
        ws2.write(r, 0, e["line_no"])
        ws2.write(r, 1, e["raw"])
        ws2.write(r, 2, e["error"])
    wb.close()

    # write Word
    doc = Document()
    for row in tqdm(parsed, desc="Generating Word"):
        p = doc.add_paragraph()
        p.add_run(f"{row['line_no']} | {row['timestamp']} | ")
        run = p.add_run(row["match"])
        run.font.color.rgb = RGBColor(255, 0, 0)
        p.add_run(f" [{row['field']}]")
    doc.save(OUTPUT_DOCX)

    # summary
    print(f"Total lines           : {len(lines)}")
    print(f"Total mobile matches  : {len(parsed)}")
    print(f"Header parse failures : {len(errors)}")

if __name__ == "__main__":
    main()
