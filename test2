#!/usr/bin/env python3
import re
import json
import xlsxwriter
from tqdm import tqdm
from docx import Document
from docx.shared import RGBColor

# === CONFIG ===
INPUT_FILE    = "input.txt"
OUTPUT_XLSX   = "ParsedLogs_Mobile.xlsx"
OUTPUT_DOCX   = "ParsedLogs_Mobile.docx"

# Mobile regex: no letter/digit immediately before/after
MOBILE_REGEX = re.compile(
    r'(?<![A-Za-z0-9])'
    r'((?:\+91[\-\s]?|91[\-\s]?|0)?[6-9]\d{9})'
    r'(?![A-Za-z0-9])'
)

# Flexible header: timestamp, thread, level, skip extras, logger
HEADER_RE = re.compile(
    r'^(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}(?:,\d+)?)\s+'
    r'\[(?P<thread>[^\]]+)\]\s+'
    r'\[(?P<level>[^\]]+)\]\s+'
    r'(?:\[[^\]]*\]\s+)*'
    r'\[(?P<logger>[^\]]+)\]\s*-\s*'
    r'(?P<rest>.+)$'
)

def flatten_json(obj, prefix=""):
    out = {}
    if isinstance(obj, dict):
        for k, v in obj.items():
            path = f"{prefix}{k}"
            if isinstance(v, (dict, list)):
                out.update(flatten_json(v, path + "."))
            else:
                out[path] = v
    elif isinstance(obj, list):
        for i, item in enumerate(obj):
            out.update(flatten_json(item, f"{prefix}[{i}]."))
    return out

def extract_json_fragments(s):
    frags = []
    pos = 0
    while True:
        start = s.find("{", pos)
        if start == -1:
            break
        depth = 0
        end = start
        for i, ch in enumerate(s[start:], start):
            if ch == "{":
                depth += 1
            elif ch == "}":
                depth -= 1
                if depth == 0:
                    end = i
                    break
        if depth != 0:
            break
        frags.append(s[start:end+1])
        pos = end + 1
    return frags

def main():
    # 1) Read nonblank lines
    lines = []
    with open(INPUT_FILE, encoding="utf-8", errors="ignore") as f:
        for ln_no, raw in enumerate(f, 1):
            txt = raw.rstrip("\n")
            if txt.strip():
                lines.append((ln_no, txt))

    parsed = []
    errors = []

    # 2) Process each line
    for ln_no, line in tqdm(lines, desc="Parsing lines"):
        m = HEADER_RE.match(line)
        if not m:
            errors.append({"line_no": ln_no, "raw": line, "error": "Header parse failed"})
            continue

        hdr = m.groupdict()
        rest = hdr.pop("rest")

        # 3) Extract JSON fragments
        frags = extract_json_fragments(rest)

        # 4) For each fragment: flatten leaves and scan raw fragment
        for idx, frag in enumerate(frags):
            # flatten JSON leaves if parseable
            leaves = {}
            try:
                obj = json.loads(frag)
                leaves = flatten_json(obj)
            except json.JSONDecodeError:
                pass  # we'll still scan raw fragment below

            # 5) Scan the raw fragment for every mobile match
            for mo in MOBILE_REGEX.finditer(frag):
                num = mo.group(1)
                # find all leaf paths containing this number
                matched_paths = [path for path, val in leaves.items() if str(val).find(num) != -1]
                if matched_paths:
                    for field in matched_paths:
                        parsed.append({
                            "line_no":  ln_no,
                            "timestamp": hdr["timestamp"],
                            "thread":    hdr["thread"],
                            "level":     hdr["level"],
                            "logger":    hdr["logger"],
                            "field":     field,
                            "match":     num
                        })
                else:
                    # fallback if no leaf path: use fragment index
                    parsed.append({
                        "line_no":  ln_no,
                        "timestamp": hdr["timestamp"],
                        "thread":    hdr["thread"],
                        "level":     hdr["level"],
                        "logger":    hdr["logger"],
                        "field":     f"fragment_{idx}",
                        "match":     num
                    })

    # 6) Write Excel
    wb = xlsxwriter.Workbook(OUTPUT_XLSX)
    ws1 = wb.add_worksheet("ParsedLogs")
    if parsed:
        headers = list(parsed[0].keys())
        for c, h in enumerate(headers):
            ws1.write(0, c, h)
        red = wb.add_format({"font_color": "red"})
        for r, row in enumerate(parsed, 1):
            for c, h in enumerate(headers):
                ws1.write(r, c, row.get(h, ""), red if h == "match" else None)

    ws2 = wb.add_worksheet("Errors")
    ws2.write_row(0, 0, ["line_no", "raw", "error"])
    for r, e in enumerate(errors, 1):
        ws2.write(r, 0, e["line_no"])
        ws2.write(r, 1, e["raw"])
        ws2.write(r, 2, e["error"])
    wb.close()

    # 7) Write Word
    doc = Document()
    for row in tqdm(parsed, desc="Generating Word"):
        p = doc.add_paragraph()
        p.add_run(f"{row['line_no']} | {row['timestamp']} | ")
        run = p.add_run(row["match"])
        run.font.color.rgb = RGBColor(255, 0, 0)
        p.add_run(f" [{row['field']}]")
    doc.save(OUTPUT_DOCX)

    # 8) Summary
    print(f"Total lines           : {len(lines)}")
    print(f"Total mobile matches  : {len(parsed)}")
    print(f"Header parse failures : {len(errors)}")

if __name__ == "__main__":
    main()
