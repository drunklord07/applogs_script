#!/usr/bin/env python3
import re
import json
import xlsxwriter
from tqdm import tqdm
from docx import Document
from docx.shared import RGBColor

# === CONFIG ===
INPUT_FILE    = "input.txt"
OUTPUT_XLSX   = "ParsedLogs_Mobile.xlsx"
OUTPUT_DOCX   = "ParsedLogs_Mobile.docx"

# Mobile regex: no letter/digit immediately before/after
MOBILE_REGEX = re.compile(
    r'(?<![A-Za-z0-9])'
    r'((?:\+91[\-\s]?|91[\-\s]?|0)?[6-9]\d{9})'
    r'(?![A-Za-z0-9])'
)

# Timestamp + header brackets: timestamp, thread, level, logger
HEADER_RE = re.compile(
    r'^(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}(?:,\d+)?)\s+'
    r'\[(?P<thread>[^\]]+)\]\s+'
    r'\[(?P<level>\w+)\s*\]\s+'
    r'\[(?P<logger>[^\]]+)\]\s*-\s*(?P<rest>.+)$'
)

def flatten_json(obj, prefix=""):
    out = {}
    if isinstance(obj, dict):
        for k, v in obj.items():
            key = f"{prefix}{k}"
            if isinstance(v, (dict, list)):
                out.update(flatten_json(v, key + "."))
            else:
                out[key] = v
    elif isinstance(obj, list):
        for i, item in enumerate(obj):
            out.update(flatten_json(item, f"{prefix}[{i}]."))
    return out

def extract_json_fragments(s):
    """Return list of (json_text, parse_error_flag) from all {...} fragments in s."""
    fragments = []
    pos = 0
    L = len(s)
    while True:
        start = s.find("{", pos)
        if start < 0:
            break
        depth = 0
        end = start
        for i, ch in enumerate(s[start:], start):
            if ch == "{":
                depth += 1
            elif ch == "}":
                depth -= 1
                if depth == 0:
                    end = i
                    break
        # if unclosed, take rest of line and mark error
        if depth != 0:
            fragments.append((s[start:].strip(), True))
            break
        fragments.append((s[start:end+1], False))
        pos = end + 1
    return fragments

def main():
    # 1) Read lines
    lines = []
    with open(INPUT_FILE, encoding="utf-8", errors="ignore") as f:
        for ln_no, raw in enumerate(f, 1):
            txt = raw.rstrip("\n")
            if txt.strip():
                lines.append((ln_no, txt))

    # 2) Parse each line
    parsed = []
    errors = []
    for ln_no, line in tqdm(lines, desc="Parsing lines"):
        m = HEADER_RE.match(line)
        if not m:
            errors.append({"line_no": ln_no, "raw": line, "error": "Header parse failed"})
            continue

        hdr = m.groupdict()
        rest = hdr.pop("rest")

        # 3) Extract JSON fragments
        frags = extract_json_fragments(rest)
        # 4) For each fragment, flatten if valid JSON
        flat = {}
        for idx, (js, bad) in enumerate(frags):
            key_base = f"payload_{idx}"
            flat[f"{key_base}"] = js
            if bad:
                flat[f"{key_base}.parse_error"] = "unclosed JSON"
                continue
            try:
                obj = json.loads(js)
                for k, v in flatten_json(obj).items():
                    flat[f"{key_base}.{k}"] = v
            except json.JSONDecodeError:
                flat[f"{key_base}.parse_error"] = "invalid JSON"

        # 5) Scan every flattened value for mobiles
        for field, val in flat.items():
            for mo in MOBILE_REGEX.finditer(str(val)):
                parsed.append({
                    "line_no":  ln_no,
                    **hdr,
                    "field":    field,
                    "match":    mo.group(1)
                })

    # 6) Write Excel
    wb = xlsxwriter.Workbook(OUTPUT_XLSX)
    ws = wb.add_worksheet("ParsedLogs")
    if parsed:
        headers = list(parsed[0].keys())
        for c, h in enumerate(headers):
            ws.write(0, c, h)
        red = wb.add_format({"font_color": "red"})
        for r, row in enumerate(parsed, 1):
            for c, h in enumerate(headers):
                val = row.get(h, "")
                ws.write(r, c, val, red if h == "match" else None)

    ws2 = wb.add_worksheet("Errors")
    ws2.write_row(0, 0, ["line_no", "raw", "error"])
    for r, e in enumerate(errors, 1):
        ws2.write(r, 0, e["line_no"])
        ws2.write(r, 1, e["raw"])
        ws2.write(r, 2, e["error"])

    wb.close()

    # 7) Write Word
    doc = Document()
    for row in tqdm(parsed, desc="Generating Word"):
        p = doc.add_paragraph()
        p.add_run(f"{row['line_no']} | {row['timestamp']} | ")
        run = p.add_run(row["match"])
        run.font.color.rgb = RGBColor(255, 0, 0)
        p.add_run(f" [{row['field']}]")
    doc.save(OUTPUT_DOCX)

    # 8) Summary
    print(f"Total lines           : {len(lines)}")
    print(f"Total mobile matches  : {len(parsed)}")
    print(f"Header parse failures : {len(errors)}")

if __name__ == "__main__":
    main()
