#!/usr/bin/env python3
import re
import json
import xlsxwriter
from tqdm import tqdm
from docx import Document
from docx.shared import RGBColor

# === CONFIG ===
INPUT_FILE  = "input.txt"
OUTPUT_XLSX = "ParsedLogs_Mobile.xlsx"
OUTPUT_DOCX = "ParsedLogs_Mobile.docx"

# Mobile regex: no letter/digit immediately before/after
MOBILE_REGEX = re.compile(
    r'(?<![A-Za-z0-9])((?:\+91[\-\s]?|91[\-\s]?|0)?[6-9]\d{9})(?![A-Za-z0-9])'
)

# Header: timestamp, thread, level, skip extras, logger
HEADER_RE = re.compile(
    r'^(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}(?:,\d+)?)\s+'
    r'\[(?P<thread>[^\]]+)\]\s+'
    r'\[(?P<level>[^\]]+)\]\s+'
    r'(?:\[[^\]]*\]\s+)*'
    r'\[(?P<logger>[^\]]+)\]\s*-\s*'
    r'(?P<rest>.+)$'
)

def flatten_json(obj, prefix=""):
    out = {}
    if isinstance(obj, dict):
        for k, v in obj.items():
            path = f"{prefix}{k}"
            if isinstance(v, (dict, list)):
                out.update(flatten_json(v, path + "."))
            else:
                out[path] = v
    elif isinstance(obj, list):
        for i, item in enumerate(obj):
            out.update(flatten_json(item, f"{prefix}[{i}]."))
    return out

def extract_fragments(s):
    """
    Return list of (frag_text) for each balanced {â€¦} in s.
    """
    frags = []
    pos = 0
    while True:
        start = s.find("{", pos)
        if start < 0:
            break
        depth = 0
        end = start
        for i, ch in enumerate(s[start:], start):
            if ch == "{":
                depth += 1
            elif ch == "}":
                depth -= 1
                if depth == 0:
                    end = i + 1
                    break
        if depth != 0:
            break
        frags.append(s[start:end])
        pos = end
    return frags

def main():
    # 1) Read non-blank lines
    lines = []
    with open(INPUT_FILE, encoding="utf-8", errors="ignore") as f:
        for ln_no, raw in enumerate(f, 1):
            txt = raw.rstrip("\n")
            if txt.strip():
                lines.append((ln_no, txt))

    parsed = []
    errors = []

    # 2) Process each line
    for ln_no, line in tqdm(lines, desc="Parsing lines"):
        m = HEADER_RE.match(line)
        if not m:
            errors.append({"line_no": ln_no, "raw": line, "error": "Header parse failed"})
            continue
        hdr = m.groupdict()
        rest = hdr.pop("rest")

        # 3) Extract each {...} fragment
        for frag in extract_fragments(rest):
            # 3a) Try JSON flattening
            leaves = {}
            try:
                obj = json.loads(frag)
                leaves = flatten_json(obj)
            except json.JSONDecodeError:
                pass

            # 3b) For every mobile in the raw fragment
            for mo in MOBILE_REGEX.finditer(frag):
                num = mo.group(1)
                # if any leaf contains this number, emit for each path
                matched = [path for path, val in leaves.items() if str(val).find(num) != -1]
                if matched:
                    for field in matched:
                        parsed.append({
                            "line_no":   ln_no,
                            "timestamp": hdr["timestamp"],
                            "thread":    hdr["thread"],
                            "level":     hdr["level"],
                            "logger":    hdr["logger"],
                            "field":     field,
                            "match":     num
                        })
                else:
                    # dynamic key= lookup within fragment text
                    prefix = frag[:mo.start()]
                    km = re.search(r'([A-Za-z0-9_]+)\s*=\s*[^,]*$', prefix)
                    field = km.group(1) if km else "fragment"
                    parsed.append({
                        "line_no":   ln_no,
                        "timestamp": hdr["timestamp"],
                        "thread":    hdr["thread"],
                        "level":     hdr["level"],
                        "logger":    hdr["logger"],
                        "field":     field,
                        "match":     num
                    })

    # 4) Write Excel
    wb = xlsxwriter.Workbook(OUTPUT_XLSX)
    ws1 = wb.add_worksheet("ParsedLogs")
    if parsed:
        cols = list(parsed[0].keys())
        for c, h in enumerate(cols):
            ws1.write(0, c, h)
        red = wb.add_format({"font_color": "red"})
        for r, row in enumerate(parsed, 1):
            for c, h in enumerate(cols):
                ws1.write(r, c, row[h], red if h == "match" else None)

    ws2 = wb.add_worksheet("Errors")
    ws2.write_row(0, 0, ["line_no","raw","error"])
    for r, e in enumerate(errors, 1):
        ws2.write(r, 0, e["line_no"])
        ws2.write(r, 1, e["raw"])
        ws2.write(r, 2, e["error"])
    wb.close()

    # 5) Write Word
    doc = Document()
    for row in tqdm(parsed, desc="Generating Word"):
        p = doc.add_paragraph()
        p.add_run(f"{row['line_no']} | {row['timestamp']} | ")
        run = p.add_run(row["match"])
        run.font.color.rgb = RGBColor(255, 0, 0)
        p.add_run(f" [{row['field']}]")
    doc.save(OUTPUT_DOCX)

    # Summary
    print(f"Total lines           : {len(lines)}")
    print(f"Total mobile matches  : {len(parsed)}")
    print(f"Header parse failures : {len(errors)}")

if __name__ == "__main__":
    main()
